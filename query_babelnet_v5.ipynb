{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = '/Users/annaysun/codenames/babelnet_v4/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_lemma_to_synsets(synsets, filename):\n",
    "    # filename denotes word\n",
    "    with open(filename, 'w') as f:\n",
    "        for synset in synsets:\n",
    "            f.write(synset + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synsets_from_lemma(word, limit):\n",
    "    url = \"https://babelnet.org/sparql/\"\n",
    "    queryString = \"\"\"\n",
    "    SELECT DISTINCT ?synset WHERE {{\n",
    "        ?entries a lemon:LexicalEntry .\n",
    "        ?entries lemon:sense ?sense .\n",
    "        ?sense lemon:reference ?synset .\n",
    "        ?entries rdfs:label \"{word}\"@en\n",
    "    }} LIMIT {limit}\n",
    "    \"\"\".format(limit=limit, word=word)\n",
    "    query = queryString.replace(\" \", \"+\")\n",
    "    fmt = urllib.parse.quote(\"application/sparql-results+json\".encode('UTF-8'), safe=\"\")\n",
    "    params = {\n",
    "        \"query\": query,\n",
    "        \"format\": fmt,\n",
    "        \"key\": \"e3b6a00a-c035-4430-8d71-661cdf3d5837\",\n",
    "    }\n",
    "    payload_str = \"&\".join(\"%s=%s\" % (k,v) for k,v in params.items())\n",
    "    \n",
    "    res = requests.get('?'.join([url, payload_str]))\n",
    "    synsets = [\n",
    "        'bn:' + r['synset']['value'].split('/')[-1].lstrip('s')\n",
    "        for r in res.json()['results']['bindings']\n",
    "    ]\n",
    "    return synsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nonautomatic_hypernyms(results):\n",
    "    return [\n",
    "        result for result in results \n",
    "        if result['pointer']['isAutomatic'] is False \n",
    "        and result['pointer']['relationGroup'] == \"HYPERNYM\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outgoing_edges_json(synset_id):\n",
    "    url = 'https://babelnet.io/v5/getOutgoingEdges'\n",
    "    params = {\n",
    "        'id': synset_id,\n",
    "        'key': 'e3b6a00a-c035-4430-8d71-661cdf3d5837',\n",
    "    }\n",
    "    headers = {'Accept-Encoding': 'gzip'}\n",
    "    res = requests.get(url=url, params=params, headers=headers)\n",
    "    return res.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_to_file(source_id, results, filename):\n",
    "    with open(filename, 'a') as f:\n",
    "        for result in results:\n",
    "            to_write = [\n",
    "                source_id,\n",
    "                result['target'],\n",
    "                result['language'],\n",
    "                result['pointer']['shortName'],\n",
    "                result['pointer']['relationGroup'],\n",
    "                str(result['pointer']['isAutomatic']),\n",
    "            ]\n",
    "            f.write('\\t'.join(to_write) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_synsets_lowered = get_synsets_from_lemma('boot', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bn:00007381n', 'bn:00083789v', 'bn:00012166n']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_synsets_lowered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_synsets_capitalized = get_synsets_from_lemma('Boot', 1)\n",
    "tmp_synsets_capitalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['africa', 'agent', 'air', 'alien', 'alps', 'amazon', 'ambulance', 'america', 'angel', 'antarctica']\n"
     ]
    }
   ],
   "source": [
    "all_codewords = []\n",
    "with open('/Users/annaysun/codenames/data/codewords.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        all_codewords.append(line.strip().lower())\n",
    "print(all_codewords[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_completed = set([\n",
    "    'buffalo', 'bear', 'bison', 'jupiter', 'moon',\n",
    "    'phoenix', 'beijing', 'cap', 'boot',\n",
    "    'india', 'germany',\n",
    "    'pipe', 'racket', 'bug', 'play', 'table',\n",
    "    'cloak', 'diamond', 'witch', 'swing', 'circle',\n",
    "    'unicorn', 'cliff', 'death', 'litter', 'car',\n",
    "    'crown', 'australia', 'roulette', 'kid', 'gas',\n",
    "    'ray', 'mammoth', 'ivory', 'key', 'piano',\n",
    "    'lab', 'school', 'lead', 'laser', 'pan',\n",
    "    'stock', 'box', 'game', 'whip', 'tube', \n",
    "    'vacuum', 'king', 'lemon', 'conductor',\n",
    "    'moscow', 'hand', 'change', 'scientist', 'worm',\n",
    "    'row', 'penguin', 'stick', 'scale', 'figure',\n",
    "    'cricket', 'ball', 'nut', 'horseshoe', 'amazon',\n",
    "    'thumb', 'spider', 'lion', 'stream', 'bomb',\n",
    "    'shark', 'africa', 'agent', 'air', 'alien',\n",
    "    'alps', 'ambulance', 'america', 'angel', 'antarctica',\n",
    "    'apple', 'arm', 'atlantis', 'aztec', 'back',\n",
    "    'band', 'bank', 'bar', 'bark', 'bat',\n",
    "    'battery', 'beach', 'beat', 'bed', 'bell',\n",
    "    'belt', 'berlin', 'bermuda', 'berry', 'bill',\n",
    "    'block', 'board', 'bolt', 'bond', 'boom',\n",
    "    'bottle', 'bow', 'bridge', 'brush', 'buck',\n",
    "    'bugle', 'button', 'calf', 'canada', 'capital',\n",
    "    'card', 'carrot', 'casino', 'cast', 'cat',\n",
    "    'cell', 'centaur', 'center', 'chair', 'charge',\n",
    "    'check', 'chest', 'chick', 'china', 'chocolate',\n",
    "    'church'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carrot casino cast cat cell centaur center chair charge check chest chick china chocolate church\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "for word in all_codewords:\n",
    "    if word in words_completed or len(word.split(' ')) != 1:\n",
    "        continue\n",
    "    words.append(word)\n",
    "    if len(words) == 15:\n",
    "        break\n",
    "print(' '.join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['carrot', 'casino', 'cast', 'cat', 'cell', 'centaur', 'center', 'chair', 'charge', 'check', 'chest', 'chick', 'china', 'chocolate', 'church']\n"
     ]
    }
   ],
   "source": [
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synsets_queried = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [08:16<00:00, 33.13s/it]\n"
     ]
    }
   ],
   "source": [
    "for word in tqdm(words):\n",
    "    synsets_capitalized = get_synsets_from_lemma(word.capitalize(), 1)\n",
    "    synsets_lowered = get_synsets_from_lemma(word.lower(), 3)\n",
    "    write_lemma_to_synsets(synsets_capitalized + synsets_lowered, file_dir+word+'_synsets')\n",
    "    for synset_0 in synsets_capitalized + synsets_lowered:\n",
    "        results_0 = get_outgoing_edges_json(synset_0)\n",
    "        append_to_file(synset_0, results_0, file_dir+word)\n",
    "        hypernyms_0 = get_nonautomatic_hypernyms(results_0)\n",
    "        for synset_1 in hypernyms_0:\n",
    "            results_1 = get_outgoing_edges_json(synset_1['target'])\n",
    "            append_to_file(synset_1['target'], results_1, file_dir+word)\n",
    "            hypernyms_1 = get_nonautomatic_hypernyms(results_1)\n",
    "            for synset_2 in hypernyms_1:\n",
    "                results_2 = get_outgoing_edges_json(synset_2['target'])\n",
    "                append_to_file(synset_2['target'], results_2, file_dir+word)\n",
    "                hypernyms_2 = get_nonautomatic_hypernyms(results_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "synsets_lowered = get_synsets_from_lemma('shark', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bn:00070919n', 'bn:00070920n', 'bn:00070921n']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synsets_lowered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'language': 'EN',\n",
       "  'pointer': {'fSymbol': '@',\n",
       "   'name': 'Hypernym',\n",
       "   'shortName': 'is-a',\n",
       "   'relationGroup': 'HYPERNYM',\n",
       "   'isAutomatic': False},\n",
       "  'target': 'bn:00006539n',\n",
       "  'weight': 0.0,\n",
       "  'normalizedWeight': 0.0},\n",
       " {'language': 'MUL',\n",
       "  'pointer': {'fSymbol': 'wd21',\n",
       "   'name': 'subclass_of',\n",
       "   'shortName': 'subclass_of',\n",
       "   'relationGroup': 'HYPERNYM',\n",
       "   'isAutomatic': False},\n",
       "  'target': 'bn:00059480n',\n",
       "  'weight': 0.0,\n",
       "  'normalizedWeight': 0.0}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypernyms_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'language': 'EN',\n",
       "  'pointer': {'fSymbol': '@',\n",
       "   'name': 'Hypernym',\n",
       "   'shortName': 'is-a',\n",
       "   'relationGroup': 'HYPERNYM',\n",
       "   'isAutomatic': False},\n",
       "  'target': 'bn:00006539n',\n",
       "  'weight': 0.0,\n",
       "  'normalizedWeight': 0.0},\n",
       " {'language': 'MUL',\n",
       "  'pointer': {'fSymbol': 'wd21',\n",
       "   'name': 'subclass_of',\n",
       "   'shortName': 'subclass_of',\n",
       "   'relationGroup': 'HYPERNYM',\n",
       "   'isAutomatic': False},\n",
       "  'target': 'bn:00059480n',\n",
       "  'weight': 0.0,\n",
       "  'normalizedWeight': 0.0}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypernyms_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
